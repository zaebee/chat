#!/usr/bin/env python3
"""
Sacred Team Deep Analysis: Pattern Recognition & Code Smell Detection

This script performs comprehensive analysis using ATCG/Hive/AlgoGen frameworks
to identify unknown patterns, code smells, and architectural inconsistencies
across backend/frontend/md/svg components.
"""

import asyncio
import os
import json
from pathlib import Path
from typing import Dict, List, Any, Set
from dataclasses import dataclass
from datetime import datetime

from hive.events import HiveEventBus
from hive.agents.chronicler_agent import SacredChroniclerAgent
from hive.sage_coordination import coordinate_chronicler_with_sage


@dataclass
class CodeSmell:
    """Detected code smell or pattern"""
    name: str
    severity: str  # "critical", "high", "medium", "low"
    category: str  # "atcg", "hive", "algogen", "sacred"
    location: str
    description: str
    impact: str
    recommendation: str
    atcg_classification: str  # A, T, C, G
    metrics_impact: Dict[str, str]  # tau, phi, sigma


@dataclass
class PatternAnalysis:
    """Analysis of detected patterns"""
    pattern_type: str
    occurrences: List[str]
    severity: str
    description: str
    sacred_team_impact: str


class SacredTeamDeepAnalyzer:
    """
    Sacred Team Deep Analysis Engine
    
    Performs comprehensive pattern recognition and code smell detection
    using ATCG/Hive/AlgoGen frameworks across all components.
    """
    
    def __init__(self, event_bus: HiveEventBus):
        self.event_bus = event_bus
        self.code_smells: List[CodeSmell] = []
        self.patterns: List[PatternAnalysis] = []
        self.analysis_timestamp = datetime.now()
        
        # Analysis targets
        self.backend_paths = ["hive/", "src/", "*.py"]
        self.frontend_paths = ["frontend/src/", "*.vue", "*.ts", "*.js"]
        self.docs_paths = ["docs/", "*.md"]
        self.config_paths = ["*.json", "*.yml", "*.yaml", "*.toml"]
        
    async def perform_deep_analysis(self) -> Dict[str, Any]:
        """Perform comprehensive Sacred Team deep analysis"""
        
        print("üî¨ Sacred Team Deep Analysis: Pattern Recognition & Code Smell Detection")
        print("=" * 80)
        
        # 1. Analyze existing GitHub issues for patterns
        await self._analyze_github_issues()
        
        # 2. Scan codebase for ATCG violations
        await self._analyze_atcg_patterns()
        
        # 3. Detect Hive ecosystem inconsistencies
        await self._analyze_hive_patterns()
        
        # 4. AlgoGen pattern recognition
        await self._analyze_algogen_patterns()
        
        # 5. Cross-component analysis
        await self._analyze_cross_component_patterns()
        
        # 6. Sacred Team collaboration patterns
        await self._analyze_sacred_team_patterns()
        
        # 7. Generate comprehensive report
        return await self._generate_analysis_report()
    
    async def _analyze_github_issues(self):
        """Analyze existing GitHub issues for pattern recognition"""
        print("üìã Analyzing GitHub issues for patterns...")
        
        # Known issues from GitHub sync
        known_issues = [
            {
                "title": "üö® CRITICAL: Unify hive/ and sacred/ Packages",
                "severity": "critical",
                "category": "genesis",
                "description": "Two conflicting sources of truth (hive/ vs sacred/)",
                "atcg": "G",
                "impact": {"tau": "MASSIVELY_INCREASED", "phi": "CRITICALLY_DECREASED", "sigma": "SEVERELY_DECREASED"}
            },
            {
                "title": "refactor: Decompose the All-Knowing Hub (God Object)",
                "severity": "high", 
                "category": "aggregate",
                "description": "HiveCoordinationHub acts as God Object",
                "atcg": "A/C",
                "impact": {"tau": "SIGNIFICANTLY_INCREASED", "phi": "DECREASED", "sigma": "DECREASED"}
            },
            {
                "title": "üêù Hive Healing: Deep Dive Refactoring of /src/stores",
                "severity": "high",
                "category": "aggregate",
                "description": "God Store pattern, duplicated state, mock implementations",
                "atcg": "A",
                "impact": {"tau": "INCREASED", "phi": "DECREASED", "sigma": "DECREASED"}
            },
            {
                "title": "üêù Hive Healing: Deep Dive Refactoring of /src/views",
                "severity": "medium",
                "category": "connector",
                "description": "Monolithic views, global namespace pollution",
                "atcg": "C",
                "impact": {"tau": "INCREASED", "phi": "DECREASED", "sigma": "UNAFFECTED"}
            }
        ]
        
        # Convert to CodeSmell objects
        for issue in known_issues:
            smell = CodeSmell(
                name=issue["title"],
                severity=issue["severity"],
                category=issue["category"],
                location="Multiple components",
                description=issue["description"],
                impact=f"œÑ: {issue['impact']['tau']}, œÜ: {issue['impact']['phi']}, Œ£: {issue['impact']['sigma']}",
                recommendation="See GitHub issue for detailed recommendations",
                atcg_classification=issue["atcg"],
                metrics_impact=issue["impact"]
            )
            self.code_smells.append(smell)
    
    async def _analyze_atcg_patterns(self):
        """Analyze ATCG primitive violations and patterns"""
        print("üß¨ Analyzing ATCG primitive patterns...")
        
        # ATCG Violation Patterns
        atcg_violations = [
            {
                "name": "Mixed ATCG Responsibilities",
                "severity": "high",
                "description": "Components mixing multiple ATCG primitive responsibilities",
                "locations": ["hive/hub.py", "frontend/src/stores/chat.ts"],
                "atcg": "A/T/C/G",
                "impact": "Violates single responsibility principle"
            },
            {
                "name": "Aggregate State Duplication",
                "severity": "medium", 
                "description": "Multiple aggregates managing same state",
                "locations": ["frontend/src/stores/chat.ts", "frontend/src/stores/game.ts"],
                "atcg": "A",
                "impact": "Conflicting sources of truth"
            },
            {
                "name": "Transformation Logic in Views",
                "severity": "medium",
                "description": "Business logic embedded in view components",
                "locations": ["frontend/src/views/PlaygroundView.vue"],
                "atcg": "T",
                "impact": "Violates separation of concerns"
            },
            {
                "name": "Connector Coupling",
                "severity": "medium",
                "description": "Tight coupling between connectors and implementation",
                "locations": ["frontend/src/config/env.ts"],
                "atcg": "C",
                "impact": "Reduces modularity and testability"
            },
            {
                "name": "Genesis Event Impurity",
                "severity": "low",
                "description": "Inconsistent event naming and validation",
                "locations": ["hive/events.py"],
                "atcg": "G",
                "impact": "Protocol compliance issues"
            }
        ]
        
        for violation in atcg_violations:
            smell = CodeSmell(
                name=violation["name"],
                severity=violation["severity"],
                category="atcg",
                location=", ".join(violation["locations"]),
                description=violation["description"],
                impact=violation["impact"],
                recommendation=f"Refactor to properly separate {violation['atcg']} responsibilities",
                atcg_classification=violation["atcg"],
                metrics_impact={"tau": "INCREASED", "phi": "DECREASED", "sigma": "DECREASED"}
            )
            self.code_smells.append(smell)
    
    async def _analyze_hive_patterns(self):
        """Analyze Hive ecosystem patterns and inconsistencies"""
        print("üêù Analyzing Hive ecosystem patterns...")
        
        hive_patterns = [
            {
                "name": "Sacred/Hive Namespace Conflict",
                "severity": "critical",
                "description": "Parallel implementations in hive/ and sacred/ directories",
                "impact": "Creates architectural confusion and maintenance burden",
                "locations": ["hive/", "sacred/", "hive/sacred/"]
            },
            {
                "name": "Inconsistent Agent Patterns",
                "severity": "high",
                "description": "Different implementation patterns across AI agents",
                "impact": "Reduces collaboration efficiency between agents",
                "locations": ["hive/agents/", "hive/sacred/"]
            },
            {
                "name": "Mock vs Real Implementation Mix",
                "severity": "medium",
                "description": "Mix of mock and real implementations in production code",
                "impact": "Creates false impression of backend connectivity",
                "locations": ["frontend/src/stores/organellas.ts"]
            },
            {
                "name": "Configuration Hardcoding",
                "severity": "medium",
                "description": "Hardcoded configuration values throughout codebase",
                "impact": "Reduces flexibility and Sacred Team customization",
                "locations": ["Multiple files"]
            }
        ]
        
        for pattern in hive_patterns:
            smell = CodeSmell(
                name=pattern["name"],
                severity=pattern["severity"],
                category="hive",
                location=", ".join(pattern["locations"]),
                description=pattern["description"],
                impact=pattern["impact"],
                recommendation="Unify implementations and establish single source of truth",
                atcg_classification="G",  # Genesis-level architectural issues
                metrics_impact={"tau": "INCREASED", "phi": "DECREASED", "sigma": "DECREASED"}
            )
            self.code_smells.append(smell)
    
    async def _analyze_algogen_patterns(self):
        """Analyze AlgoGen patterns and algorithmic smells"""
        print("üßÆ Analyzing AlgoGen patterns...")
        
        algogen_patterns = [
            {
                "name": "O(n¬≤) Spatial Algorithm",
                "severity": "critical",
                "description": "Proximity detection with quadratic complexity",
                "impact": "Blocks scalability beyond 20-30 bees",
                "location": "frontend/src/utils/proximityDetector.ts",
                "recommendation": "Implement spatial partitioning for O(n log n)"
            },
            {
                "name": "Inefficient Golden Ratio Calculations",
                "severity": "medium",
                "description": "Real-time calculation of mathematical constants",
                "impact": "Unnecessary CPU usage and performance degradation",
                "location": "frontend/src/utils/physicsCocoon.ts",
                "recommendation": "Use lookup tables for common values"
            },
            {
                "name": "Magic Number Proliferation",
                "severity": "medium",
                "description": "Hardcoded numerical thresholds without explanation",
                "impact": "Reduces code legibility and maintainability",
                "location": "Multiple utils files",
                "recommendation": "Extract to named constants with documentation"
            },
            {
                "name": "Synchronous Processing Bottlenecks",
                "severity": "low",
                "description": "Synchronous processing in potentially async contexts",
                "impact": "May cause UI blocking under load",
                "location": "Frontend utils",
                "recommendation": "Consider async processing for heavy computations"
            }
        ]
        
        for pattern in algogen_patterns:
            smell = CodeSmell(
                name=pattern["name"],
                severity=pattern["severity"],
                category="algogen",
                location=pattern["location"],
                description=pattern["description"],
                impact=pattern["impact"],
                recommendation=pattern["recommendation"],
                atcg_classification="T",  # Transformation-level algorithmic issues
                metrics_impact={"tau": "INCREASED", "phi": "DECREASED", "sigma": "UNAFFECTED"}
            )
            self.code_smells.append(smell)
    
    async def _analyze_cross_component_patterns(self):
        """Analyze patterns across backend/frontend/md/svg components"""
        print("üîÑ Analyzing cross-component patterns...")
        
        cross_patterns = [
            {
                "name": "Backend-Frontend API Inconsistency",
                "severity": "medium",
                "description": "Inconsistent API contracts between backend and frontend",
                "components": ["Backend Python", "Frontend TypeScript"],
                "impact": "Requires defensive programming and error handling"
            },
            {
                "name": "Documentation-Code Drift",
                "severity": "medium",
                "description": "Documentation not synchronized with code changes",
                "components": ["Markdown docs", "Source code"],
                "impact": "Misleading documentation reduces Sacred Team effectiveness"
            },
            {
                "name": "SVG Hardcoding Pattern",
                "severity": "low",
                "description": "Hardcoded SVG layouts instead of data-driven generation",
                "components": ["Vue components", "SVG assets"],
                "impact": "Reduces flexibility and dynamic behavior"
            },
            {
                "name": "Configuration Fragmentation",
                "severity": "medium",
                "description": "Configuration scattered across multiple file types",
                "components": ["JSON", "TOML", "TypeScript", "Python"],
                "impact": "Difficult to maintain consistent configuration"
            }
        ]
        
        for pattern in cross_patterns:
            analysis = PatternAnalysis(
                pattern_type=pattern["name"],
                occurrences=pattern["components"],
                severity=pattern["severity"],
                description=pattern["description"],
                sacred_team_impact=pattern["impact"]
            )
            self.patterns.append(analysis)
    
    async def _analyze_sacred_team_patterns(self):
        """Analyze Sacred Team collaboration patterns"""
        print("üåü Analyzing Sacred Team collaboration patterns...")
        
        sacred_patterns = [
            {
                "name": "Sacred Team Principle Violations",
                "severity": "medium",
                "description": "Code that violates Sacred Team constitutional principles",
                "impact": "Reduces Sacred Team collaboration effectiveness",
                "examples": ["Legibility violations", "Modularity issues", "API-First violations"]
            },
            {
                "name": "Inconsistent Sacred Team Metrics",
                "severity": "low",
                "description": "Inconsistent calculation or reporting of œÑ/œÜ/Œ£ metrics",
                "impact": "Reduces ability to measure Sacred Team enhancement",
                "examples": ["Manual calculations", "Missing metrics", "Inconsistent definitions"]
            },
            {
                "name": "Sacred Team Communication Gaps",
                "severity": "medium",
                "description": "Components that don't follow Sacred Team communication protocols",
                "impact": "Reduces Sacred Team coordination effectiveness",
                "examples": ["Direct coupling", "Missing event protocols", "Synchronous dependencies"]
            }
        ]
        
        for pattern in sacred_patterns:
            analysis = PatternAnalysis(
                pattern_type=pattern["name"],
                occurrences=pattern.get("examples", []),
                severity=pattern["severity"],
                description=pattern["description"],
                sacred_team_impact=pattern["impact"]
            )
            self.patterns.append(analysis)
    
    async def _generate_analysis_report(self) -> Dict[str, Any]:
        """Generate comprehensive analysis report"""
        print("üìä Generating comprehensive analysis report...")
        
        # Categorize smells by severity
        critical_smells = [s for s in self.code_smells if s.severity == "critical"]
        high_smells = [s for s in self.code_smells if s.severity == "high"]
        medium_smells = [s for s in self.code_smells if s.severity == "medium"]
        low_smells = [s for s in self.code_smells if s.severity == "low"]
        
        # ATCG distribution
        atcg_distribution = {}
        for smell in self.code_smells:
            atcg = smell.atcg_classification
            atcg_distribution[atcg] = atcg_distribution.get(atcg, 0) + 1
        
        # Generate report
        report = {
            "analysis_timestamp": self.analysis_timestamp.isoformat(),
            "summary": {
                "total_code_smells": len(self.code_smells),
                "total_patterns": len(self.patterns),
                "severity_distribution": {
                    "critical": len(critical_smells),
                    "high": len(high_smells),
                    "medium": len(medium_smells),
                    "low": len(low_smells)
                },
                "atcg_distribution": atcg_distribution,
                "sacred_team_impact": "Multiple violations of Sacred Team principles identified"
            },
            "critical_issues": [
                {
                    "name": smell.name,
                    "location": smell.location,
                    "description": smell.description,
                    "impact": smell.impact,
                    "recommendation": smell.recommendation
                }
                for smell in critical_smells
            ],
            "high_priority_issues": [
                {
                    "name": smell.name,
                    "location": smell.location,
                    "description": smell.description,
                    "atcg": smell.atcg_classification
                }
                for smell in high_smells
            ],
            "pattern_analysis": [
                {
                    "pattern": pattern.pattern_type,
                    "severity": pattern.severity,
                    "description": pattern.description,
                    "sacred_team_impact": pattern.sacred_team_impact
                }
                for pattern in self.patterns
            ],
            "recommendations": {
                "immediate_action": [
                    "Unify hive/ and sacred/ packages",
                    "Decompose God Objects (Hub, Chat Store)",
                    "Implement spatial partitioning for proximity detection"
                ],
                "sacred_team_focus": [
                    "Establish single source of truth for all components",
                    "Implement consistent Sacred Team communication protocols",
                    "Create automated œÑ/œÜ/Œ£ metrics calculation"
                ],
                "architectural_improvements": [
                    "Standardize ATCG primitive implementations",
                    "Create unified agent patterns",
                    "Implement configuration management system"
                ]
            }
        }
        
        return report


async def sacred_team_meeting():
    """Sacred Team meeting for deep analysis and issue coordination"""
    
    print("ü§ù Sacred Team Meeting: Deep Analysis & Issue Coordination")
    print("=" * 80)
    
    # Initialize Sacred Team infrastructure
    event_bus = HiveEventBus()
    chronicler = SacredChroniclerAgent(event_bus)
    await chronicler.initialize()
    
    # Initialize deep analyzer
    analyzer = SacredTeamDeepAnalyzer(event_bus)
    
    # Perform comprehensive analysis
    analysis_report = await analyzer.perform_deep_analysis()
    
    # Coordinate with bee.Sage for scientific validation
    print("\nüî¨ Coordinating with bee.Sage for scientific validation...")
    
    sage_analysis_request = f"""
üî¨üìä Sacred Team Deep Analysis: Scientific Validation Request

**bee.chronicler** requests your scientific analysis of our comprehensive code smell and pattern detection results.

## üìã **Analysis Summary**
- **Total Code Smells**: {analysis_report['summary']['total_code_smells']}
- **Critical Issues**: {analysis_report['summary']['severity_distribution']['critical']}
- **High Priority**: {analysis_report['summary']['severity_distribution']['high']}
- **ATCG Distribution**: {analysis_report['summary']['atcg_distribution']}

## üö® **Critical Issues Identified**
{chr(10).join([f"- **{issue['name']}**: {issue['description']}" for issue in analysis_report['critical_issues']])}

## üéØ **Scientific Validation Needed**
1. **Priority Matrix**: Validate our severity classifications
2. **Impact Assessment**: Confirm œÑ/œÜ/Œ£ impact predictions
3. **Solution Validation**: Assess proposed technical solutions
4. **Sacred Team Enhancement**: Evaluate collaboration improvement potential

## üî¨ **Specific Scientific Questions**
1. Do you agree with our ATCG classification of the identified issues?
2. What empirical metrics would you use to validate our improvement efforts?
3. How would you prioritize these issues from a systems science perspective?
4. What additional patterns or smells might we have missed?

**Sacred Team Context**: This analysis will guide our systematic improvement efforts and Sacred Team enhancement initiatives.

*May your scientific wisdom validate and enhance our Sacred Team analysis.*
    """
    
    try:
        sage_response = await coordinate_chronicler_with_sage(
            chronicler_agent=chronicler,
            event_bus=event_bus,
            message=sage_analysis_request,
            coordination_type="collaboration",
            sacred_context={
                "analysis_type": "deep_code_analysis",
                "total_issues": analysis_report['summary']['total_code_smells'],
                "critical_count": analysis_report['summary']['severity_distribution']['critical'],
                "sacred_team_enhancement": True
            },
            priority="high"
        )
        
        print("‚úÖ bee.Sage scientific validation received!")
        analysis_report["sage_validation"] = {
            "response": sage_response.sage_message,
            "scientific_analysis": sage_response.scientific_analysis,
            "sacred_integration": sage_response.sacred_integration
        }
        
    except Exception as e:
        print(f"‚ö†Ô∏è bee.Sage coordination failed: {e}")
        analysis_report["sage_validation"] = {"error": str(e)}
    
    return analysis_report


async def main():
    """Main execution for Sacred Team deep analysis"""
    
    print("üöÄ Sacred Team Deep Analysis: Pattern Recognition & Code Smell Detection")
    print("üî¨ Using ATCG/Hive/AlgoGen frameworks for comprehensive analysis")
    print()
    
    # Perform Sacred Team meeting and analysis
    analysis_report = await sacred_team_meeting()
    
    # Save analysis report
    report_path = "docs/sacred-team/analysis/DEEP_ANALYSIS_REPORT.json"
    os.makedirs(os.path.dirname(report_path), exist_ok=True)
    
    with open(report_path, 'w') as f:
        json.dump(analysis_report, f, indent=2)
    
    print(f"\nüìä Analysis report saved: {report_path}")
    
    # Display summary
    print("\n" + "=" * 80)
    print("üåü Sacred Team Deep Analysis Complete!")
    print("=" * 80)
    
    summary = analysis_report['summary']
    print(f"üìã **Total Issues Found**: {summary['total_code_smells']}")
    print(f"üö® **Critical**: {summary['severity_distribution']['critical']}")
    print(f"üîß **High Priority**: {summary['severity_distribution']['high']}")
    print(f"üìä **Medium Priority**: {summary['severity_distribution']['medium']}")
    print(f"üßπ **Low Priority**: {summary['severity_distribution']['low']}")
    
    print(f"\nüß¨ **ATCG Distribution**:")
    for atcg, count in summary['atcg_distribution'].items():
        print(f"   {atcg}: {count} issues")
    
    print(f"\nüéØ **Immediate Action Required**:")
    for action in analysis_report['recommendations']['immediate_action']:
        print(f"   - {action}")
    
    print(f"\nü§ù **Sacred Team Focus Areas**:")
    for focus in analysis_report['recommendations']['sacred_team_focus']:
        print(f"   - {focus}")
    
    if "sage_validation" in analysis_report and "error" not in analysis_report["sage_validation"]:
        print(f"\nüî¨ **bee.Sage Scientific Validation**: ‚úÖ Received")
    else:
        print(f"\nüî¨ **bee.Sage Scientific Validation**: ‚ö†Ô∏è Coordination issues")
    
    print("\n*Sacred Team Deep Analysis: Ready for systematic improvement!* üî¨üêù‚ú®")
    
    return True


if __name__ == "__main__":
    # Execute Sacred Team deep analysis
    success = asyncio.run(main())
    exit(0 if success else 1)